{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the following configs are no longer maintained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from config import Config\n",
    "from model import UNet2D\n",
    "from train import Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test 6 - `(32 32 32) (4 4 4) (0 64)` - T\n",
    "Change the schedular to ExponentialLR.\n",
    "\"\"\"\n",
    "\n",
    "# configurations\n",
    "config = Config()\n",
    "config.batch_size  = 16\n",
    "config.num_workers = 8\n",
    "# learning rate\n",
    "config.lr = 0.0001\n",
    "# checkpoint\n",
    "config.checkpoint_path = os.path.join('..', \"checkpoints/test_6\")\n",
    "config.save_pt_epoch = True\n",
    "# dataset\n",
    "config.dim_frame = [32, 32, 32]\n",
    "config.up_sample = [4, 4, 4]\n",
    "config.mol_range  = [0, 64]\n",
    "# model\n",
    "net = UNet2D(config)\n",
    "# train\n",
    "trainer = Train(config)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test 5 - `(32 32 32) (2 4 4) (0 16)` - T\n",
    "Now our goal is to train a (2 4 4) network with high accuracy where the frame \n",
    "size is at least (128 128 128). The result shows that the validation loss is \n",
    "slowly decrease and the learning rate scheduler is not function properly. We \n",
    "modity the schedular to exponential learning rate.\n",
    "\"\"\"\n",
    "\n",
    "# configurations\n",
    "config = Config()\n",
    "config.batch_size = 8\n",
    "# learning rate  \n",
    "config.lr = 0.0001\n",
    "# running log\n",
    "config.logdir = os.path.join( # type: ignore\n",
    "    '..', \"runs/test_5\") \n",
    "# checkpoint\n",
    "config.checkpoint_path = os.path.join(\n",
    "    '..', \"checkpoints/test_5\")\n",
    "config.save_pt_epoch = True\n",
    "# dataset\n",
    "config.dim_frame = [64, 64, 64]\n",
    "config.up_sample = [2, 4, 4]\n",
    "config.mol_range  = [0, 32]\n",
    "# model\n",
    "net       = UNet2D(config)\n",
    "# train\n",
    "trainer = Train(config, net,)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test 4 - `(32 32 32) (4 4 4) (0 64)` - T\n",
    "We test 32 32 32 frame with upsampling 4, 4, 4. Setting the molecular range \n",
    "0-64, which has almost same density as above test. The result shows that the \n",
    "network can correctly do the locolization task. \n",
    "\"\"\"\n",
    "\n",
    "# configurations\n",
    "config = Config()\n",
    "config.lr = 0.0001\n",
    "config.batch_size = 8\n",
    "config.dim_frame = [32, 32, 32]\n",
    "config.up_sample = [4, 4, 4]\n",
    "config.mol_range  = [0, 64]\n",
    "config.logdir = os.path.join( # type: ignore\n",
    "    '..', \"runs/test_4\") \n",
    "config.checkpoint_path = os.path.join(\n",
    "    '..', \"checkpoints/test_4\")\n",
    "config.save_pt_epoch = True\n",
    "# model and criterion\n",
    "net       = UNet2D(config)\n",
    "criterion = Criterion(config)\n",
    "# train\n",
    "trainer = Train(config, net, criterion)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test 3 - `(16 16 16) (4 4 4) (0 12)` - T\n",
    "To see if the gauss reason in test 2 is right, we can decrase the size of frame \n",
    "by 2 in scale, which keep the sparcity same to test 1. All other parameters set \n",
    "same as test 1. \n",
    "The test 1-3 shows that, the density is the most important factor to our final \n",
    "result. Test 1 and 3 has the same density so they have almost same result. Then, \n",
    "we may have three way to modify our framework:\n",
    "- If nonzero is  0, load checkpoint and decrease leanring rate. In this way, we \n",
    "  can set a relative large learning rate. \n",
    "- Set a high mollecular range and let the network to learn what should study. \n",
    "\"\"\"\n",
    "\n",
    "# configurations\n",
    "config = Config()\n",
    "config.lr = 0.0001\n",
    "config.batch_size = 8\n",
    "config.dim_frame = [16, 16, 16]\n",
    "config.up_sample = [4, 4, 4]\n",
    "config.checkpoint_path = os.path.join('..', \"checkpoints/test_3\")\n",
    "config.save_pt_epoch = True\n",
    "# model and criterion\n",
    "net = UNet2D(config)\n",
    "# train\n",
    "trainer = Train(config, net)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test 2 - `(32 32 32) (4 4 4) (0 12)` - F\n",
    "All zero. When optimize the network, although lum can provide gradiant to let \n",
    "position away from the label become 0, when there are too many dark area, the \n",
    "network may shift the task to let all value become zero instead of find the mean\n",
    "of Gaussian. Although the lum of each single pixel change independently, the \n",
    "network will still make the task of all pixel same. Thus, we should prevent from\n",
    "the network to go to the wrong direction during training. \n",
    "In test 1, this may not be a big problem since quadruple upsampling is much \n",
    "sparce than double upsampling in test 1.\n",
    "\"\"\"\n",
    "\n",
    "# configurations\n",
    "config = Config()\n",
    "config.lr = 0.0001\n",
    "config.batch_size = 8\n",
    "config.dim_frame = [32, 32, 32]\n",
    "config.up_sample = [4, 4, 4]\n",
    "config.checkpoint_path = os.path.join('..', \"checkpoints/test_2\")\n",
    "config.save_pt_epoch = True\n",
    "# model and criterion\n",
    "net = UNet2D(config)\n",
    "# train\n",
    "trainer = Train(config, net)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test 1 - `(32 32 32) (2 2 2) (0 12)` - T\n",
    "\"\"\"\n",
    "# configurations\n",
    "config = Config()\n",
    "config.lr = 0.001\n",
    "config.batch_size = 8\n",
    "config.dim_frame = [32, 32, 32]\n",
    "config.up_sample = [2, 2, 2]\n",
    "config.checkpoint_path = os.path.join('..', \"checkpoints/test_1\")\n",
    "config.save_pt_epoch = True\n",
    "# model and criterion\n",
    "net = UNet2D(config)\n",
    "# train\n",
    "trainer = Train(config)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-SMLFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
