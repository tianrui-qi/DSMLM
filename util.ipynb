{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" frame preprocess\n",
    "Convert the Xunamen output \n",
    "from (64 512 512)pixel ( 65 130 130)nm 16bit\n",
    "to   (32 512 512)pixel (130 130 130)nm 16bit\n",
    "To save storage space.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import tifffile\n",
    "import tqdm\n",
    "\n",
    "frames_load_fold = \"E:/frames\"\n",
    "frames_save_fold = \"D:/frames\"\n",
    "\n",
    "frames_list = os.listdir(frames_load_fold)\n",
    "for index in tqdm.tqdm(range(len(frames_list))):\n",
    "    # read 16 bit tiff, note that the order of os.listdir is not guaranteed\n",
    "    frame = tifffile.imread(\n",
    "        os.path.join(frames_load_fold, frames_list[index])\n",
    "    ).astype(np.float32)\n",
    "    frame = torch.from_numpy(frame).float()\n",
    "    # 64 512 512 -> 32 512 512\n",
    "    frame = F.interpolate(\n",
    "        frame.unsqueeze(0).unsqueeze(0), \n",
    "        size = (32, 512, 512)\n",
    "    ).squeeze(0).squeeze(0).half()\n",
    "    # save 16 bit with file name formation\n",
    "    tifffile.imwrite(\n",
    "        \"{}/{:05}.tif\".format(frames_save_fold, int(frames_list[index][11:-4])),\n",
    "        frame.numpy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" mlist preprocess\n",
    "(x, y, z, FWHM_x, FWHM_y, FWHM_z, peak) -> (z, x, y, var_z, var_x, var_y, peak)\n",
    "x, y, z start index from 1 to 0, i.e., 1-64 to 0-63\n",
    "z pixel size from 65 to 130, (64, 512, 512) -> (32, 512, 512)\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import h5py\n",
    "import scipy.io\n",
    "import tqdm\n",
    "\n",
    "mlists_load_fold = \"D:/hela/coords_20231003\"\n",
    "mlists_save_fold = \"D:/hela/mlists\"\n",
    "\n",
    "mlists_list = os.listdir(mlists_load_fold)\n",
    "for index in tqdm.tqdm(range(len(mlists_list))):\n",
    "    # read mlist\n",
    "    try:\n",
    "        with h5py.File(\n",
    "            os.path.join(mlists_load_fold, mlists_list[index]), 'r'\n",
    "        ) as file: mlist = file['storm_coords'][()].T\n",
    "    except OSError:\n",
    "        _, mlist = scipy.io.loadmat(\n",
    "            os.path.join(mlists_load_fold, mlists_list[index])\n",
    "        ).popitem()\n",
    "    mlist = torch.from_numpy(mlist).float()\n",
    "\n",
    "    # (x, y, z, FWHM_x, FWHM_y, FWHM_z, peak) -> \n",
    "    # (z, x, y, FWHM_z, FWHM_x, FWHM_y, peak)\n",
    "    mlist = mlist[:, [2, 0, 1, 5, 3, 4, 6]]\n",
    "    # index from (0 - 64) to (-0.5 - 63.5)\n",
    "    mlist[:, 0:3] = mlist[:, 0:3] - 0.5\n",
    "    # (65, 130, 130)nm -> (130, 130, 130)nm\n",
    "    mlist[:, 0] = (mlist[:, 0] + 0.5) / 2 - 0.5\n",
    "    mlist[:, 3] =  mlist[:, 3] / 2\n",
    "    # (x, y, z, FWHM_x, FWHM_y, FWHM_z, peak) -> \n",
    "    # (z, x, y, var_z, var_x, var_y, peak)\n",
    "    mlist[:, 3:6] = (mlist[:, 3:6] / 2.355) ** 2\n",
    "\n",
    "    # save\n",
    "    scipy.io.savemat(\n",
    "        \"{}/{:05}.mat\".format(mlists_save_fold, int(mlists_list[index][11:-4])),\n",
    "        {\"storm_coords\": mlist.numpy()}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" mlist2label \n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "import os\n",
    "import tifffile\n",
    "import h5py\n",
    "import scipy.io\n",
    "import tqdm\n",
    "\n",
    "# dimensional config\n",
    "dim_frame = Tensor([ 32, 512, 512]).int()   # (C, H, W), (130, 130, 130)nm\n",
    "up_sample = Tensor([  4,   8,   8]).int()   # (C, H, W)\n",
    "dim_label = dim_frame * up_sample\n",
    "# data path\n",
    "frames_load_fold = \"D:/SMLFM/frames\"\n",
    "mlists_load_fold = \"D:/SMLFM/mlists\"\n",
    "temp_save_fold   = \"D:/SMLFM/temp\"\n",
    "data_save_fold   = \"D:/temp\"\n",
    "\n",
    "# file name list\n",
    "frames_list = os.listdir(frames_load_fold)\n",
    "mlists_list = os.listdir(mlists_load_fold)\n",
    "# create folder\n",
    "if not os.path.exists(data_save_fold): os.makedirs(data_save_fold)\n",
    "\n",
    "# drift\n",
    "drift  = torch.from_numpy(\n",
    "    np.loadtxt(os.path.join(temp_save_fold, \"drift.csv\"), delimiter=',')\n",
    ").float()\n",
    "drift *= up_sample / Tensor([4, 4, 4]).int()\n",
    "drift  = drift.round().int()\n",
    "\n",
    "result = torch.zeros(*dim_label.tolist())\n",
    "for index in tqdm.tqdm(\n",
    "    range(len(frames_list)), desc=data_save_fold, unit=\"frame\"\n",
    "):\n",
    "    mlist = None\n",
    "    try:\n",
    "        with h5py.File(os.path.join(\n",
    "            mlists_load_fold, mlists_list[index]\n",
    "        ), 'r') as file: mlist = file['storm_coords'][()].T\n",
    "    except OSError:\n",
    "        _, mlist = scipy.io.loadmat(\n",
    "            os.path.join(mlists_load_fold, mlists_list[index])\n",
    "        ).popitem()\n",
    "    mlist = torch.from_numpy(mlist).float()\n",
    "\n",
    "    # up sample the molecular list\n",
    "    mlist[:, 0:3]  = (mlist[:, 0:3] + 0.5) * up_sample - 0.5\n",
    "    # drift correction for molecular list\n",
    "    mlist[:, 0:3] += drift[index]\n",
    "    # round and clip\n",
    "    mlist[:, 0:3]  = torch.round(mlist[:, 0:3])\n",
    "    mlist[:, 0:3]  = torch.clip(mlist[:, 0:3], torch.zeros_like(dim_label), dim_label - 1)\n",
    "\n",
    "    mlist[:,   6] /= 6.5\n",
    "\n",
    "    # label\n",
    "    for i in range(mlist.shape[0]):\n",
    "        mean = mlist[i, 0:3]\n",
    "        peak = torch.clip(mlist[i, 6], 0, 1)\n",
    "        result[tuple(mean.int())] += peak\n",
    "\n",
    "    # save after combine 1, 2, 4, 8, 16... frames\n",
    "    current_frame = index + 1\n",
    "    if current_frame & (current_frame - 1) == 0 or index == 45000 - 1:\n",
    "        tifffile.imwrite(\n",
    "            \"{}/{:05}.tif\".format(data_save_fold, current_frame),\n",
    "            result.numpy()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" concatenate two 3D subframes into a 3D frame \n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import os\n",
    "\n",
    "LT_fold = \"D:/488-dl-(09-25-00-05)/\"  # left or top\n",
    "RD_fold = \"D:/488-dl-(09-25-05-29)/\"  # right or down\n",
    "FN_fold = \"D:/488-dl-(09-25-00-29)/\"  # final\n",
    "axis = 2    # 1 for vertical, 2 for horizontal\n",
    "\n",
    "if not os.path.exists(FN_fold): os.makedirs(FN_fold)\n",
    "for i in range(len(os.listdir(LT_fold))): tifffile.imwrite(\n",
    "    os.path.join(FN_fold, os.listdir(LT_fold)[i]),\n",
    "    np.concatenate([\n",
    "        tifffile.imread(os.path.join(LT_fold, os.listdir(LT_fold)[i])), \n",
    "        tifffile.imread(os.path.join(RD_fold, os.listdir(RD_fold)[i])),\n",
    "    ], axis=axis)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" resolution\n",
    "Measure the resolution by cluster.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import scipy.io\n",
    "import os\n",
    "import tqdm\n",
    "from typing import List\n",
    "\n",
    "def get_cluster_mlist(\n",
    "    clsuter_list: np.ndarray, wide: int, mlists_load_fold: str\n",
    ") -> List[np.ndarray]:\n",
    "    # file name list\n",
    "    mlists_list = os.listdir(mlists_load_fold)\n",
    "\n",
    "    # use to store final result\n",
    "    cluster_mlist = [[] for _ in range(len(clsuter_list))]\n",
    "\n",
    "    # go through all mlists and get the mlist for each cluster\n",
    "    for index in tqdm.tqdm(range(45000), unit=\"mlist\"):\n",
    "        # read a mlist out of 45000 mlists\n",
    "        _, mlist = scipy.io.loadmat(\n",
    "            os.path.join(mlists_load_fold, mlists_list[index])\n",
    "        ).popitem()\n",
    "        # (H W D), index start from 1 -> (D H W), index start from 0\n",
    "        mlist = mlist[:, [2, 0, 1]] - 1\n",
    "        # [64 512 512] -> [32 512 512]\n",
    "        mlist[:, 0] = (mlist[:, 0] + 0.5) / 2 - 0.5\n",
    "\n",
    "        for c in range(len(clsuter_list)):\n",
    "            # find the submlist that match the position with current cluster\n",
    "            position = clsuter_list[c]  # (D H W)\n",
    "            submlist = mlist\n",
    "            submlist = submlist[submlist[:, 0] >= position[0] - wide]\n",
    "            submlist = submlist[submlist[:, 0] <= position[0] + wide]\n",
    "            submlist = submlist[submlist[:, 1] >= position[1] - wide]\n",
    "            submlist = submlist[submlist[:, 1] <= position[1] + wide]\n",
    "            submlist = submlist[submlist[:, 2] >= position[2] - wide]\n",
    "            submlist = submlist[submlist[:, 2] <= position[2] + wide]\n",
    "\n",
    "            # add the molecular in submlist to cluster_mlist\n",
    "            for i in range(len(submlist)): cluster_mlist[c].append(submlist[i])\n",
    "\n",
    "    # mena center each cluster's mlist\n",
    "    for k in range(len(cluster_mlist)):\n",
    "        cluster_mlist[k] = np.array(cluster_mlist[k])\n",
    "        if cluster_mlist[k].shape[0] == 0: continue\n",
    "\n",
    "        gmm = GaussianMixture(n_components=1)\n",
    "        gmm.fit(cluster_mlist[k])\n",
    "        cluster_mlist[k] -= gmm.means_[0]\n",
    "\n",
    "    return cluster_mlist  # [K, num of mol in each cluster]\n",
    "\n",
    "# load cluster position\n",
    "cluster_list = np.array([  # (D H W), index start from 0\n",
    "    [85, 1603, 523 ],\n",
    "    [88, 1437, 512 ],\n",
    "    [86, 1447, 493 ],\n",
    "    [51, 1546, 685 ],\n",
    "    [53, 1576, 867 ],\n",
    "    [57, 1768, 1110],\n",
    "    [58, 1686, 1214],\n",
    "    [61, 670 , 482 ],\n",
    "    [59, 574 , 607 ],\n",
    "    [62, 531 , 1239],\n",
    "    [62, 712 , 1416],\n",
    "    [61, 1059, 1671]\n",
    "])\n",
    "# since position in cluster_list find in super resolution image\n",
    "cluster_list = (cluster_list + 0.5) / 4 - 0.5\n",
    "\n",
    "# go through all mlists and get the mlist (mean centered) for each cluster\n",
    "cluster_mlist = get_cluster_mlist(cluster_list, 0.5, \"D:/mlists\")\n",
    "\n",
    "# combine all cluster's mlist and fit a gmm\n",
    "all_mlist = []\n",
    "for k in range(len(cluster_mlist)): all_mlist.extend(cluster_mlist[k])\n",
    "gmm = GaussianMixture(n_components=1)\n",
    "gmm.fit(all_mlist)\n",
    "\n",
    "# information\n",
    "print(gmm.covariances_)\n",
    "print(gmm.means_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMLFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
